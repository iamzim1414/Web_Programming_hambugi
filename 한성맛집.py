import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re

# ë§í¬ CSV ë¶ˆëŸ¬ì˜¤ê¸°
link_df = pd.read_csv("correct_diningcode_links.csv")
urls = link_df['Full URL'].tolist()
results = []

# âœ… APIë¡œ ìƒí˜¸ëª… ê¸°ë°˜ ì „í™”ë²ˆí˜¸ + ëŒ€í‘œ ë¦¬ë·° ê°€ì ¸ì˜¤ê¸°
def fetch_data_by_name(address):
    try:
        url = "https://im.diningcode.com/API/isearch/"
        headers = {
            "Content-Type": "application/x-www-form-urlencoded",
            "User-Agent": "Mozilla/5.0"
        }
        data = {
            "query": address,
            "order": "r_score",
            "search_type": "poi_search",
            "mode": "poi",
            "page": "1",
            "size": "10"
        }
        response = requests.post(url, data=data, headers=headers)
        if response.status_code == 200:
            items = response.json().get("result_data", {}).get("poi_section", {}).get("list", [])
            for item in items:
                if address in item.get("road_addr", ""):
                    return {
                        "ì „í™”ë²ˆí˜¸": item.get("phone", "ì •ë³´ì—†ìŒ"),
                        "ëŒ€í‘œë¦¬ë·°": item.get("display_review", {}).get("review_cont", "ë¦¬ë·° ì—†ìŒ"),
                        "ì¹´í…Œê³ ë¦¬": item.get("category","ì •ë³´ ì—†ìŒ")
                    }
        return {"ì „í™”ë²ˆí˜¸": "ì •ë³´ì—†ìŒ", "ëŒ€í‘œë¦¬ë·°": "ë¦¬ë·° ì—†ìŒ", "ì¹´í…Œê³ ë¦¬": "ì •ë³´ì—†ìŒ"}
    except:
        return {"ì „í™”ë²ˆí˜¸": "ì •ë³´ì—†ìŒ", "ëŒ€í‘œë¦¬ë·°": "ë¦¬ë·° ì—†ìŒ", "ì¹´í…Œê³ ë¦¬": "ì •ë³´ì—†ìŒ"}

# âœ… í¬ë¡¤ë§ ì‹œì‘
for idx, url in enumerate(urls):
    print(f"ğŸ” ({idx+1}/{len(urls)}) ì²˜ë¦¬ ì¤‘: {url}")
    
    try:
        res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(res.text, 'html.parser')

        # ìƒí˜¸ëª…
        name = soup.select_one('#div_profile h1')
        name = name.text.strip() if name else ""

        # img url 
        img1 = soup.select_one('#div_profile > div.s-list.pic-grade > div.store-pic > div:nth-child(2) > img')
        img2 = soup.select_one('#div_profile > div.s-list.pic-grade > div.store-pic > div:nth-child(2) > img')
         
        # ë©”ë‰´ ì •ë³´
        menu_items = []
        menu_list = soup.select("div.menu-info.short ul li")

        for li in menu_list:
            name_tag = li.select_one("p.l-txt.Restaurant_MenuItem span")
            price_tag = li.select_one("p.r-txt.Restaurant_MenuPrice")
            
            menu_name = name_tag.text.strip() if name_tag else ""
            price = price_tag.text.strip() if price_tag else ""
            
            if menu_name or price:
                menu_items.append(f"{menu_name} - {price}")

        #ì˜ì—…ì‹œê°„
        # ì˜¤ëŠ˜ ìš´ì˜ì‹œê°„
        all_hours = []
        today_hours_tag = soup.select_one("div.busi-hours-today > ul > li > p.r-txt")
        all_hours.append(f"ëª©: {today_hours_tag.text.strip('ì˜ì—…ì‹œê°„ ')}")    

        # ìš”ì¼ë³„ ì „ì²´ ìš´ì˜ì‹œê°„
        
        rows = soup.select("div.busi-hours ul li")

        for row in rows:
            day = row.select_one("p.l-txt")
            day_text = day.text.strip()
            match = re.search(r'\((.*?)\)', day_text)
            day = match.group(1) if match else ""
            hours = row.select_one("p.r-txt")
            if day and hours:
                all_hours.append(f"{day}: {hours.text.strip()}")


        # ì£¼ì†Œ
        address_parts = soup.select('#div_profile ul > li.locat > a')
        address = " ".join([a.text.strip() for a in address_parts[:4]])

        # í‰ì ë“¤
        def extract_ratings(soup):
            ë§›, ê°€ê²©, ì‘ëŒ€ = 0.0, 0.0, 0.0
            point_section = soup.select_one('p.point-detail')
            if point_section:
                children = point_section.find_all(['span', 'i'])
                label = None
                for tag in children:
                    if tag.name == 'span':
                        label = tag.text.strip()
                    elif tag.name == 'i' and label:
                        score = float(tag.text.strip()) if tag.text.strip().replace('.', '', 1).isdigit() else 0.0
                        if 'ë§›' in label:
                            ë§› = score
                        elif 'ê°€ê²©' in label:
                            ê°€ê²© = score
                        elif 'ì‘ëŒ€' in label:
                            ì‘ëŒ€ = score
                        label = None
            return ë§›, ê°€ê²©, ì‘ëŒ€
        
        # í‰ì ë“¤
        ë§›í‰ì , ê°€ê²©í‰ì , ì‘ëŒ€í‰ì  = extract_ratings(soup)
        í‰ê· í‰ì  = round((ë§›í‰ì  + ê°€ê²©í‰ì  + ì‘ëŒ€í‰ì ) / 3, 2) if any([ë§›í‰ì , ê°€ê²©í‰ì , ì‘ëŒ€í‰ì ]) else 0.0



        # ë¶„ìœ„ê¸° íƒœê·¸ & ìƒì„¸ì •ë³´
        ë¶„ìœ„ê¸°íƒœê·¸ = soup.select_one('ul.app-arti li:nth-child(2)')
        ë¶„ìœ„ê¸°íƒœê·¸ = ë¶„ìœ„ê¸°íƒœê·¸.text.strip() if ë¶„ìœ„ê¸°íƒœê·¸ else ""
        
        



        

        # ğŸ”‘ API í˜¸ì¶œ (ìƒí˜¸ëª… ê¸°ë°˜)
        api_info = fetch_data_by_name(address)

        results.append({
            "ìƒí˜¸ëª…": name,
            "ëŒ€í‘œì‚¬ì§„1" : img1,
            "ëŒ€í‘œì‚¬ì§„2" : img2,
            "ì£¼ì†Œ": address,
            "ë§› í‰ì ": ë§›í‰ì ,
            "ê°€ê²© í‰ì ": ê°€ê²©í‰ì ,
            "ì‘ëŒ€ í‰ì ": ì‘ëŒ€í‰ì ,
            "í‰ê·  í‰ì ": í‰ê· í‰ì ,
            "ì „í™”ë²ˆí˜¸": api_info["ì „í™”ë²ˆí˜¸"],
            "ëŒ€í‘œ ë¦¬ë·°": api_info["ëŒ€í‘œë¦¬ë·°"],
            "ì¹´í…Œê³ ë¦¬": api_info["ì¹´í…Œê³ ë¦¬"],
            "ë¶„ìœ„ê¸° íƒœê·¸": ë¶„ìœ„ê¸°íƒœê·¸,
            "ë©”ë‰´ ì •ë³´" : menu_items,
            "ë§í¬": url,
            
            "ìš´ì˜ì‹œê°„" : all_hours
        })

        time.sleep(1)

    except Exception as e:
        print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
        continue

# ì €ì¥
df = pd.DataFrame(results)
df.to_csv("í†µí•©_ë§›ì§‘ì •ë³´.csv", index=False, encoding="utf-8-sig")
print("âœ… ì™„ë£Œ ë° CSV ì €ì¥!")
